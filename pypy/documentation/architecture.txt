Overview on PyPy's current architecture (Mar. 2005)
===================================================


PyPy - an implementation of Python in Python
--------------------------------------------

It has become a tradition in the development of computer languages to
implement each language in itself. This serves many purposes. By doing so,
you demonstrate the versatility of the language, and its applicability for
large projects.  A compiler/interpreter is close to as complex as software
ever gets.

The PyPy project aims to do this for Python and has made some significant
progress. In a number of one week sprints, each attracting approximately
10 developers each, we made an almost complete implementation of Python in
Python. Currently it is rather slow, benchmarking at a factor 4000 times
slower than regular Python (henceforth referred to as CPython).

In the next step of the project, we will generate C code from the source
of PyPy, thereby reducing the speed penalty.

Later in the project, we will introduce optimisation (following the ideas
of Psyco) that should make PyPy run faster than CPython.

An important aspect of implementing Python in Python is the high level of
abstraction and compactness of the language. This yields an implementation
that is easier to understand than the one done in C.

Another carrying idea in PyPy is to build the implementation in the form
of a number of independent modules with clearly defined API's. This eases
reuse and allows experimenting with multiple implementations of specific
features.

Our rather complete and 2.3-compliant interpreter is about 22000 lines of
code, with another 7000 lines of unit tests (we also pass a number of
CPython's own tests).  If we include the tools, the parts related to code
analysis and generation, and the standard library modules ported from C,
PyPy is now 55000 lines of code and 20000 lines of tests.


Higher level picture
-------------------------------------

The various parts of PyPy have always been under more or less heavy
refactoring during our five one-week sprints in 2003.  However, the
higher level architecture remains rather simple and unchanged.  There
are two independent basic subsystems:

- the *standard interpreter* which implements the Python language 
  and is composed out of two components:

  - the *plain interpreter* which is responsible for interpreting 
    code objects and implementing bytecodes,

  - the *standard object space* which implements creation, access and
    modification of application level objects,

  Note that the *standard interpreter* can run fine on top of CPython 
  (the C Implementation of Python led by Guido van Rossum) but of course
  the double-interpretation penalty lets us interpret python programs
  rather slowly. 

- the *translation process* which aims at producing a different (low-level)
  representation of our standard interpreter.  The *translation process* 
  is done in three steps: 

  - producing a *flow graph* representation of the standard interpreter. 
    A combination of a *plain interpreter* and a *flow object space*
    performs "abstract interpretation" to record the flow of objects
    and execution throughout a python program into such a *flow graph*. 

  - the *annotator* which performs type inference on the flow graph 

  - the *translator* which translates the (annotated) flow graph into
    another language, currently Pyrex/C and LISP.  

Please note that we are using the term *interpreter* most often in
reference to the *plain interpreter* which just knows enough to read,
dispatch and implement *bytecodes* thus shuffling objects around on the
stack and between namespaces.  The (plain) interpreter is completly
ignorant of how to access, modify or construct objects and their
structure and thus delegates such operations to a so called "Object Space". 

XXX mention Parser and compiler (we have one available since the Berlin
sprint but it is not integrated)

The Interpreter
===============

The interpreter handles python code objects. The interpreter can build
code objects from Python sources, when needed, by invoking Python's
builtin compiler (we also have a way of constructing those code objects
from python code only, but we have not integrated it yet).  Code objects
are a nicely preprocessed, structured representation of source code, and
their main content is *bytecode*.  In addition, code objects also know
how to create a *frame* object which has the responsibility to
*interpret* a code object's bytecode.  Each bytecode is implemented by a
python function, which, in turn, delegates operations on
application-level objects to an object space. 

The Object Space
================

The object space creates all objects and knows how to perform operations
on the objects. You may think of an object space as being a library
offering a fixed API, a set of *operations*, with implementations that
correspond to the known semantics of Python objects.  An example of an
operation is *add*: add's implementations are, for example, responsible
for performing numeric addition when add works on numbers, concatenation
when add works on built-in sequences.

All object-space operations take and return "application level" objects.
There is only one, very simple, object-space operation which allows the
interpreter to gain some knowledge about the value of an
application-level object: ``is_true()``, which returns a boolean
interpreter-level value.  This is necessary to implement, for example,
if-statements (or rather, to be pedantic, to implement the
conditional-branching bytecodes into which if-statements get compiled). 

We currently have three working object spaces which can be plugged into
the interpreter:

- The Standard Object Space, which is an almost complete implementation 
  of the various Python objects. This is the main focus of this
  document, since the Standard Object Space, together with the
  interpreter, is the foundation of our Python implementation. 

- the Flow Object Space, which transforms a python program into a
  flow-graph representation.  The Flow Object Space performs this
  transformation task through "abstract interpretation", which we will
  explain later in this document.

- the Trace Object Space, which wraps e.g. the standard 
  object space in order to trace the execution of bytecodes, 
  frames and object space operations. 

The Standard Object Space
=========================

The Standard Object Space implements python objects and types, and all
operations on them.  It is thus an essential component in order to reach
CPython compatibility. 

The implementations of ints, floats, strings, dicts, lists, etc, all
live in separate files, and are bound together by a "multimethod"
mechanism.  Multimethods allow a caller - most notably the interpreter -
to stay free from knowing anything about objects' implementations.  Thus
multimethods implement a way of delegating to the right implementation
based on the passed in objects (objects previously created by the same
subsystem).  We examine how the multimethod mechanism works through an
example.

We consider the add-operation of ``int`` and ``float`` objects, and
disregard all other object types for the moment.  There is one
multimethod ``add``, and both relevant implementations, ``add(intimpl,
intimpl)`` and ``add(floatimpl, floatimpl)``, *register* with that one
``add`` multimethod.

When we have the expression ``2+3`` in our application program, the
interpreter creates an application-level object containing ("wrapping")
the value ``2`` and another one containing the value ``3``.  We talk
about them as ``W_Int(2)`` and ``W_Int(3)`` respectively. The
interpreter then calls the Standard Object Space with ``add(W_Int(2),
W_Int(3))``.

The Object Space then examines the objects passed in, and delegates
directly to the ``add(intimpl, intimpl)`` function: since this is a
"direct hit", the multimethod immediately dispatches the operation to
the correct implementation, i.e., the one registered as the
implementation for this signature.

If the multimethod doesn't have any registered functions for the exact
given signature, as would be the case for example for the expression
``2+3.0``, the multimethod tests if it can use coercion to find a
function with a signature that works. In this case we would coerce
``W_Int(2)`` to ``W_Float(2.0)`` in order to find a function in the
multimethod that has a correct signature. Note that the multimethod
mechanism is still considered a major refactoring target, since it is
not easy to get it completly right, fast and accurate.  

Application-level and interpreter-level execution and objects
=============================================================

Since Python is used for implementing all of our code base, there is a
crucial distinction to be aware of: *interpreter-level* objects versus
*application level* objects.  The latter are the ones that you deal with
when you write normal python programs.  Interpreter-level code, however,
cannot invoke operations nor access attributes from application-level
objects.  You will immediately recognize any interpreter level code in
PyPy, because all variable and object names start with a ``w_``, which
indicates that they are "wrapped" application-level values. 

Let's show the difference with a simple example.  To sum the contents of
two variables ``a`` and ``b``, typical application-level code is ``a+b``
-- in sharp contrast, typical interpreter-level code is ``space.add(w_a,
w_b)``, where ``space`` is an instance of an object space, and ``w_a``
and ``w_b`` are typical names for the *wrapped* versions of the two
variables.  

It helps to remember how CPython deals with the same issue: interpreter
level code, in CPython, is written in C, and thus typical code for the
addition is ``PyNumber_Add(p_a, p_b)`` where ``p_a`` and ``p_b`` are C
variables of type ``PyObject*``. This is very similar to how we write
our interpreter-level code in Python.

Moreover, in PyPy we have to make a sharp distinction between
interpreter- and application-level *exceptions*: application exceptions
are always contained inside an instance of ``OperationError``.  This
makes it easy to distinguish failures in our interpreter-level code from
failures appearing in a python application level program that we are
interpreting.


Application level is often preferable 
-------------------------------------

Application-level code is substantially higher-level, and therefore
correspondingly easier to write and debug.  For example, suppose we want
to implement the ``update`` method of dict objects.  Programming at
application level, we can write an obvious, simple implementation, one
that looks like an **executable definition** of ``update``, for
example::

    def update(self, other):
        for k in other.keys():
            self[k] = other[k]

If we had to code only at interpreter level, we would have to code
something much lower-level and involved, say something like::

    def update(space, w_self, w_other):
        w_keys = space.call_method(w_other, 'keys')
        w_iter = space.iter(w_keys)
        while True:
            try: w_key = space.next(w_iter)
            except NoValue: break
            w_value = space.getitem(w_other, w_key)
            space.setitem(w_self, w_key, w_value)

This interpreter-level implementation looks much more similar to the C
source code, although it is probably still more readable.  In any case,
it should be obvious that the application-level implementation is
definitely more readable, more elegant and more maintainable than the
interpreter-level one.

In fact, in almost all parts of PyPy, you find application level code in
the middle of interpreter-level code.  Apart from some bootstrapping
problems (application level functions need a certain initialization
level of the object space before they can be executed), application
level code is usually preferable.  We have an abstraction (called
'Gateway') which allows the caller of a function to remain ignorant of
whether a particular function is implemented at application or
interpreter level. 

Wrapping
========

The ``w_`` prefixes so lavishly used in the previous example indicate,
by PyPy coding convention, that we are dealing with *wrapped* objects,
that is, interpreter-level objects which the object space constructs
to implement corresponding application-level objects.  Each object
space supplies ``wrap`` and ``unwrap``, ``int_w``, ``interpclass_w``,
etc. operations that move between the two levels for objects of simple
built-in types; each object space also implements other Python types
with suitable interpreter-level classes with some amount of internal
structure.

For example, an application-level Python ``list`` is implemented as an
instance of ``W_ListObject``, which has an instance attribute
``ob_item`` (an interpreter-level list which contains the
application-level list's items as wrapped objects) and another attribute
``ob_size`` which records the application-level list's length (we want
to be able to do "over-allocation" in ``ob_item``, for the same reasons
of performance that lead CPython to do it, and therefore the length of
``ob_item`` is allowed to be greater than the length of the
application-level list -- it is for this reason that the length in
question has to be explicitly recorded in ``ob_size``).

See ``wrapping.txt`` for more details.


RPython, the Flow Object Space and translation
==============================================

One of PyPy's -term objectives is to enable translation of our
interpreter and standard object space into a lower-level language.  In
order for our translation and type inference mechanisms to work
effectively, we need to restrict the dynamism of our interpreter-level
Python code at some point.  However, in the start-up phase, we are
completly free to use all kind of nice python constructs, including
metaclasses and execution of dynamically constructed strings.  However,
when the initialization phase (mainly, the function
``objspace.initialize()``) finishes, all code objects involved need to
adhere to a (non-formally defined) more static subset of Python:
Restricted Python, also known as 'RPython'. 

The Flow Object Space then, with the help of our plain interpreter,
works through those initialized "RPython" code objects.  The result of
this *abstract interpretation* is a flow graph: yet another
representation of a python program, but one which is suitable for
applying translation and type inference techniques.  The nodes of the
graph are basic blocks consisting of Object Space operations, flowing
of values, and an exitswitch to one, two or multiple links which connect
each basic block to other basic blocks. 

The flow graphs are fed as input into the Annotator. The Annotator,
given entry point types, infers the types of values that flow through
the program variables.  Here, one of the informal definitions of RPython
comes into play: RPython code is restricted in such a way that the
translator is able to compile low-level **typed** code.  How much
dynamism we allow in RPython depends, and is restricted by, the Flow
Object Space and the Annotator implementation.  The more we can improve
this translation phase, the more dynamism we can allow.  In some cases,
however, it will probably be more feasible and practical to just get rid
of some of the dynamism we use in our interpreter level code.  It is
mainly because of this trade-off situation that we don't currently try
to formally define 'RPython'. 

The actual low-level code (and, in fact, also other high-level code) is
emitted by "visiting" the type-annotated flow graph. Currently, we have
a Pyrex-producing backend, and a Lisp-producing backend.  We use (a
slightly hacked version of) Pyrex to generate C libraries.  Since Pyrex
also accepts plain non-typed python code, we can test translation even
though type annotation is not complete.  

Trace Object Space 
==================

A recent addition is the Trace Object space, which wraps a standard  
object space in order to trace all object space operations,
frame creation, deletion and bytecode execution.  The ease with which
the Trace Object Space was implemented at the Amsterdam Sprint
underlines the power of the Object Space abstraction.  (Of course, the
previously-implemented Flow Object Space producing the flow graph
already was proof enough). 

There are certainly many more possibly useful Object Space ideas, such
as a ProxySpace that connects to a remote machine where the actual
operations are performed. At the other end, we wouldn't need to change
object spaces at all in order to extend or modify the interpreter, e.g.
by adding or removing some bytecodes.  Thus, the interpreter and
object-space cooperation nicely splits the python runtime into two
reasonably-independent halves, cooperating along a reasonably narrow
interface, and suitable for multiple separate implementations.
