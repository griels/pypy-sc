============================================================
      Encapsulating low-level implementation aspects
============================================================

.. contents::
.. sectnum::


Abstract
========

It has always been a major goal of PyPy to not force implementation
decisions.  This means that even after the implementation of the
standard interpreter has been written we are still able to experiment
with different approaches to memory management or concurrency and to
target wildly different platforms such as the Java Virtual Machine or
a very memory-limited embedded environment.

We do this by allowing the encapsulation of these low level aspects as
well defined parts of the translation process.

In the following document, we give examples of aspects that have been
successfully encapsulated in more detail and contrast the potential of
our approach with CPython.


Background
==========

One of the better known significant modifications to CPython are
Christian Tismer's "stackless" patches [#]_, which allow for far more
flexible control flow than the typical function call/return supported by
CPython.  Originally implemented as a series of invasive patches,
Christian found that maintaining these patches as CPython itself was
further developed was time consuming to the point of no longer being
able to work on the new functionality that was the point of the
exercise.

One solution would have been for the patches to become part of core
CPython but this was not done partly because the code that fully enabled
stackless required widespread modifications that made the code harder to
understand (as the "stackless" model contains control flow that is not
easily expressable in C, the implementation became much less
"natural" in some sense).

With PyPy, however, it is possible to obtain this flexible control
flow whilst retaining transparent implementation code as the necessary
modifications can be implemented as a localized translation aspect,
and indeed this was done at the Paris sprint in a couple of days (as
compared to XXX weeks for the original stackless patches).

Of course, this is not the only aspect that can be so decided a
posteriori, during translation.


Translation aspects
===================

Our standard interpreter [#]_ is implemented at a very high level of
abstraction.  This has a number of happy consequences, among which is
enabling the encapsulation of language aspects as described in this
document.  For example, the implementation code simply makes no
reference to memory management, which clealy gives the translator
complete freedom to decide about this aspect.  This constrasts with
CPython where the decision to use reference counting is reflected tens
or even hundreds of times in each C source file in the codebase.

As described in [#]_, producing a Python implementation from the
source of our standard interpreter involves various stages: the
initialization code is run, the resulting code is annotated, typed and
finally translated.  By the nature of the task, the encapsulation of
*low-level aspects* mainly affects the typer and the translation
process.  At the coarsest level, the selection of target platform
involves writing a new backend -- still a significant task, but much
much easier than writing a complete implementation of Python!

Other aspects affect different levels, as their needs require.  The
remainder of this section describes a few aspects that we have
successfully enscapsulated.


Stacklessness
-------------

The stackless modifications are mostly implemented in the C backend
but also change the low-level graphs in small ways.  The total changes
vonly required about 300 lines of source, vindicating our abstract
approach.

XXX More!


Multiple Interpreters
---------------------

Another implementation detail that causes tension between functionality
and both code clarity and memory consumption in CPython is the issue of
multiple independent interpreters in the same process.  In CPython there
is a partial implementation of this idea in the "interpreter state" API,
but the interpreters produced by this are not truly independent -- for
instance the dictionary that contains interned strings is implemented as
file-level static object, and is thus shared between the interpreters.
A full implementation of this idea would entirely eschew the use of file
level statics and place all interpreter-global data in some large
structure, which would hamper readability and maintainability.  In
addition, in many situations it is necessary to determine which
interpreter a given object is "from" -- and this is not possible in
CPython largely because of the memory overhead that adding a 'interp'
pointer to all Python objects would create.

In PyPy, all of our implementation code manipulates an explicit object
space instance, so that the situation of multiple interpreters is
handled entirely automatically.  If there is only one space instance, it
is regarded as a pre-constructed constant and the space object pointer
(though not its non-constant contents) disappears from the produced
source.  If there are two or more such instances, a 'space' attribute
will be automatically added to all application objects (or more
precisely, it will not be removed by the translation process), the best
of both worlds.


Concurrency
-----------

The aspect of CPython's implementation that has probably caused more
discussion than any other mentioned here is that of the threading
model.  Python has supported threads since version 1.5 with what is
commonly referred to as the "Global Interpreter Lock" or GIL; the
execution of bytecodes is serialized such that only one thread can be
executing Python code at one time.  This has the benefit of being
relatively unintrusive and not too complex, but has the disadvantage
that multi-threaded, computation-bound Python code does not gain
performance on multi-processor machines.

PyPy will offer the opportunity to experiment with different models,
although currently we only offer a version with no thread support and
another with a GIL-like model.  (We also plan to support soon "green"
software-only threads in the Stackless model described above, but
obviously this would not solve the multi-processor scalability issue.)

The future work in this direction is to collect the numerous possible
approaches that have between thought out along the years and
e.g. presented on the CPython development mailing list.  Most of them
have never been tried out in CPython, for lack of necessary resources.
A number of them are clearly easy to try out in PyPy, at least in an
experimental version that would allow its costs to be assessed -- for
example, various forms of object-level locking.


Memory Management
-----------------

A final low-level aspect is that of memory management.  As mentioned
above, CPython's decision to use a garbage collector based on
reference counting is reflected throughout the source.  In the
implementation code of PyPy, it is not, and in fact the standard
interpreter can currently be compiled to use a reference counted
scheme or Boehm's `garbage collector for C`_.

.. _`garbage collector for C`: http://www.hpl.hp.com/personal/Hans_Boehm/gc/

Another advantage of the aspect oriented approach shows itself most
clearly with this memory management aspect: that of correctness.
Although reference counting is a fairly simple scheme, writing code
for CPython requires that the programmer make a large number of
not-quite-trivial decisions about the refcounting code and experience
suggests that mistakes will always creep in, leading to crashes or
leaks.  While tools exist to help find these mistakes, it is surely
better to not write the reference count manipulations at all and this
is what PyPy's approach allows.  Writing the code that emits the
correct reference count manipulations is surely harder than writing
any one piece of explicit refcounting code, but once it's done and
tested, it just works without further effort.


Evaluation Strategy
-------------------

Possibly the most radical aspect to tinker with is the evaluation
strategy.  The thunk object space wraps the standard object space to
allow the production of "lazily computed objects", objects whose
values are only calculated when needed, and to allow the global and
total replacement of one object with another.  The thunk object space
is mostly meant as an example of what our approach can acheive -- the
combination of side-effects and lazy evaluation is not easy to
understand.


Conclusion
==========

Although still a work in progress, we believe that the successes we
have had in enscapsulating implementation aspects justifies the
approach we have taken.


References
==========

.. [#] http://www.stackless.com

.. [#] `standard interpreter`_ in this context means the code which
       implements the interpreter and the standard object space.

.. [#] `PyPy - Architecture Overview`_

.. _`standard interpreter`: architecture.html#standard-interpreter
.. _`PyPy - Architecture Overview`: architecture.html
